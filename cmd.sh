RES_OPTIONS="no-reverse" NCCL_IB_HCA=^mlx5_2 deepspeed  --hostfile hostfile_hwmoe src/train.py --deepspeed examples/deepspeed/ds_z2_config_hhw.json --stage telechat_hwmoe_pt --model_name_or_path /gemini/space/thu/TeleChat-2B-A05B-exp16/ --train_from_scratch  --trust_remote_code --dataset default --tokenized_path /gemini/space/thu/receieve_wangzihan/Megatron-LM-core_r0.6.0_dropout_HWMoE/converted_dataset   --finetuning_type full --output_dir  ./saves/TeleChat-2B-A05B-exp16 --per_device_train_batch_size 2 --gradient_accumulation_steps 2 --lr_scheduler_type cosine --logging_steps 1 --save_steps 1000 --learning_rate 3e-4  --warmup_ratio 0.01  --num_train_epochs 1 --plot_loss --preprocessing_num_workers 40 --ddp_timeout 18000 --bf16 --cutoff_len 8192 --flash_attn auto --do_train  2>&1 | tee TeleChat-2B-A05B-exp16.log
RES_OPTIONS="no-reverse" NCCL_IB_HCA=^mlx5_2 deepspeed  --hostfile hostfile_hwmoe src/train.py --deepspeed examples/deepspeed/ds_z2_config_hhw.json --stage telechat_hwmoe_pt --model_name_or_path /gemini/space/thu/TeleChat-2B-A05B-exp8/  --train_from_scratch  --trust_remote_code --dataset default --tokenized_path /gemini/space/thu/receieve_wangzihan/Megatron-LM-core_r0.6.0_dropout_HWMoE/converted_dataset   --finetuning_type full --output_dir  ./saves/TeleChat-2B-A05B-exp8  --per_device_train_batch_size 2 --gradient_accumulation_steps 2 --lr_scheduler_type cosine --logging_steps 1 --save_steps 1000 --learning_rate 3e-4  --warmup_ratio 0.01  --num_train_epochs 1 --plot_loss --preprocessing_num_workers 40 --ddp_timeout 18000 --bf16 --cutoff_len 8192 --flash_attn auto --do_train  2>&1 | tee TeleChat-2B-A05B-exp8.log
RES_OPTIONS="no-reverse" NCCL_IB_HCA=^mlx5_2 deepspeed  --hostfile hostfile_hwmoe src/train.py --deepspeed examples/deepspeed/ds_z2_config_hhw.json --stage telechat_hwmoe_pt --model_name_or_path /gemini/space/thu/TeleChat-2B-A05B-exp4/  --train_from_scratch  --trust_remote_code --dataset default --tokenized_path /gemini/space/thu/receieve_wangzihan/Megatron-LM-core_r0.6.0_dropout_HWMoE/converted_dataset   --finetuning_type full --output_dir  ./saves/TeleChat-2B-A05B-exp4  --per_device_train_batch_size 2 --gradient_accumulation_steps 2 --lr_scheduler_type cosine --logging_steps 1 --save_steps 1000 --learning_rate 3e-4  --warmup_ratio 0.01  --num_train_epochs 1 --plot_loss --preprocessing_num_workers 40 --ddp_timeout 18000 --bf16 --cutoff_len 8192 --flash_attn auto --do_train  2>&1 | tee TeleChat-2B-A05B-exp4.log
RES_OPTIONS="no-reverse" NCCL_IB_HCA=^mlx5_2 deepspeed  --hostfile hostfile_hwmoe src/train.py --deepspeed examples/deepspeed/ds_z2_config_hhw.json --stage telechat_hwmoe_pt --model_name_or_path /gemini/space/thu/TeleChat-2B-A05B-exp2/  --train_from_scratch  --trust_remote_code --dataset default --tokenized_path /gemini/space/thu/receieve_wangzihan/Megatron-LM-core_r0.6.0_dropout_HWMoE/converted_dataset   --finetuning_type full --output_dir  ./saves/TeleChat-2B-A05B-exp2  --per_device_train_batch_size 2 --gradient_accumulation_steps 2 --lr_scheduler_type cosine --logging_steps 1 --save_steps 1000 --learning_rate 3e-4  --warmup_ratio 0.01  --num_train_epochs 1 --plot_loss --preprocessing_num_workers 40 --ddp_timeout 18000 --bf16 --cutoff_len 8192 --flash_attn auto --do_train  2>&1 | tee TeleChat-2B-A05B-exp2.log